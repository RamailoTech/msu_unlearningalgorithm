{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Unlearning (MU) for Erase diff algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **1: Environment Setup**\n",
    " \n",
    "In this section, we set up our Python environment and install the necessary packages. For reproducibility, it’s best to use a virtual environment.\n",
    "\n",
    "\n",
    "Instructions:\n",
    "\n",
    "* Create and activate your virtual environment.\n",
    "\n",
    "* Install our package `unlearn_diff`.\n",
    "\n",
    "\n",
    "**Prerequisities**\n",
    "\n",
    "Ensure conda is installed on your system. You can install Miniconda or Anaconda:\n",
    "\n",
    "* Miniconda (recommended): https://docs.conda.io/en/latest/miniconda.html\n",
    "\n",
    "* Anaconda: https://www.anaconda.com/products/distribution\n",
    "\n",
    "After installing conda, ensure it is available in your PATH by running. You may require to restart the terminal session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create venv if you are using python script.\n",
    "\n",
    "!python -m venv unlearning-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating your virtual environment, if you're working in a notebook, select the kernel associated with that environment. If you're using a terminal instead, activate the environment with:\n",
    "\n",
    "`source unlearning-env/bin/activate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install our packaging unlearn_diff\n",
    "\n",
    "!pip install unlearn_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create unlearn_diff conda environment  and activate\n",
    "\n",
    "Use this command to create environment:\n",
    "\n",
    "`create_env`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!create_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate conda environment:\n",
    "\n",
    "`conda activate <env_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Downloading the Dataset**\n",
    "\n",
    "After you install the package, you can use the following commands to download.\n",
    "\n",
    "1. i2p:\n",
    "\n",
    "* Sample: \n",
    "\n",
    "```bash \n",
    "     download_data sample i2p\n",
    "```\n",
    "\n",
    "* Full: \n",
    "```bash \n",
    "     download_data full i2p\n",
    "```\n",
    "\n",
    "2. quick_canvas:\n",
    "\n",
    "* Sample: \n",
    "\n",
    "```bash \n",
    "     download_data sample quick_canvas\n",
    "```\n",
    "\n",
    "* Full: \n",
    "\n",
    "```bash \n",
    "     download_data full quick_canvas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading sample i2p dataset\n",
    "\n",
    "!download_data sample i2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading sample quick_canvas dataset:\n",
    "\n",
    "!download_data sample quick_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded datasets, verify the Downloaded Files.\n",
    "\n",
    "* ls data/i2p-dataset/sample/\n",
    "\n",
    "* ls -lh ./data/quick-canvas-dataset/sample/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Downloading models**\n",
    "\n",
    "* compvis: \n",
    "\n",
    "```bash \n",
    "     download_model compvis\n",
    "```\n",
    "\n",
    "* diffuser: \n",
    "\n",
    "```bash\n",
    "     download_model diffuser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download compvis model\n",
    "\n",
    "#! download_model compvis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download diffuser model\n",
    "\n",
    "#! download_model diffuser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **MU**\n",
    "\n",
    "**Run Train**\n",
    "\n",
    "The default configuration for training is provided by erase_diff_train_mu. You can run the training with the default settings as follows:\n",
    "\n",
    "\n",
    "```python\n",
    "from mu.algorithms.erase_diff.algorithm import EraseDiffAlgorithm\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "algorithm = EraseDiffAlgorithm(\n",
    "    erase_diff_train_mu\n",
    ")\n",
    "algorithm.run()\n",
    "```\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "**Overriding the Default Configuration**\n",
    "\n",
    "If you need to override the existing configuration settings, you can specify your custom parameters (such as ckpt_path and raw_dataset_dir) directly when initializing the algorithm. For example:\n",
    "\n",
    "```python\n",
    "from mu.algorithms.erase_diff.algorithm import EraseDiffAlgorithm\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "algorithm = EraseDiffAlgorithm(\n",
    "    erase_diff_train_mu,\n",
    "    use_sample = True\n",
    ")\n",
    "algorithm.run()\n",
    "```\n",
    "\n",
    "<span style=\"color: red;\"><br>Note: When fine-tuning the model, if you want to use a sample dataset, set use_sample=True (default).Otherwise, set use_sample=False to use the full dataset.<br></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine unlearning with quick canvas dataset\n",
    "\n",
    "\n",
    "from mu.algorithms.erase_diff.algorithm import EraseDiffAlgorithm\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "algorithm = EraseDiffAlgorithm(\n",
    "    erase_diff_train_mu,\n",
    "    ckpt_path=\"/home/ubuntu/Projects/UnlearnCanvas/UnlearnCanvas/machine_unlearning/models/compvis/style50/compvis.ckpt\",\n",
    "    raw_dataset_dir=\"data/quick-canvas-dataset/sample\",\n",
    "    use_sample = True, #uses sample dataset\n",
    "    template_name = \"Abstractionism\",\n",
    "    dataset_type = \"unlearncanvas\",\n",
    "    devices = \"0\"\n",
    ")\n",
    "algorithm.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine unlearning with i2p dataset\n",
    "\n",
    "\n",
    "from mu.algorithms.erase_diff.algorithm import EraseDiffAlgorithm\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_i2p\n",
    "\n",
    "algorithm = EraseDiffAlgorithm(\n",
    "    erase_diff_train_i2p,\n",
    "    ckpt_path=\"/home/ubuntu/Projects/UnlearnCanvas/UnlearnCanvas/machine_unlearning/models/compvis/style50/compvis.ckpt\",\n",
    "    raw_dataset_dir=\"data/i2p-dataset/sample\",\n",
    "    num_samples = 1,\n",
    "    dataset_type = \"i2p\",\n",
    "    template = \"i2p\",\n",
    "    template_name = \"self-harm\",\n",
    "    use_sample = True #uses sample dataset\n",
    "    \n",
    ")\n",
    "algorithm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of MU\n",
    "\n",
    "The evaluation framework is used to assess the performance of models after applying machine unlearning.\n",
    "\n",
    "config descriptions:\n",
    "\n",
    "* erase_diff_evaluation_config : default evaluation config for erase_dif\n",
    "* ckpt_path: finetuned model path for erase_diff algorithm.\n",
    "* classifier_ckpt_path: Path to classifier model\n",
    "* refrence_dir: original dataset dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu.algorithms.erase_diff import EraseDiffEvaluator\n",
    "from mu.algorithms.erase_diff.configs import (\n",
    "    erase_diff_evaluation_config\n",
    ")\n",
    "\n",
    "evaluator = EraseDiffEvaluator(\n",
    "    erase_diff_evaluation_config,\n",
    "    ckpt_path=\"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\", #finetuned model path \n",
    "    classifier_ckpt_path = \"/home/ubuntu/Projects/models/classifier_ckpt_path/style50_cls.pth\",\n",
    "    reference_dir= \"data/quick-canvas-dataset/sample/\"\n",
    ")\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">**Output for evalaution will be saved to the given directory `Outputs/eval_results/mu_results/erase_diff/`** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run Attacks**\n",
    "\n",
    "Before running attacks, download dataset for attack. Run the following command in terminal.\n",
    "\n",
    "`generate_attack_dataset --prompts_path data/prompts/prompts.csv --concept i2p_nude --save_path outputs/dataset --num_samples 1`\n",
    "\n",
    "Here, prompts_path is the path of csv containing prompt, concept is the name of the concept for organizing output file, save_path is the directory where generated images and metadata will be saved, num_samples is the number of images to generate per prompt.\n",
    "\n",
    "1. **Hard Prompt Attack - compvis**\n",
    "\n",
    "After performing unlearning, make sure to use the same fine-tuned model checkpoint (generated during unlearning) for performing the attack.\n",
    "Use the following code if you wish to run the hard prompt attack using the CompVis model directly (without converting it into Diffusers format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.nudity import no_attack_esd_nudity_classifier_compvis_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def run_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "    \"task.compvis_ckpt_path\" :\"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\",\n",
    "    \"task.dataset_path\" : \"/home/ubuntu/Projects/Palistha/unlearn_diff_attack/outputs/dataset/i2p_nude\",\n",
    "   \"task.compvis_config_path\" : erase_diff_train_mu.model_config_path ,\n",
    "    \"attacker.no_attack.dataset_path\" : \"/home/ubuntu/Projects/Palistha/unlearn_diff_attack/outputs/dataset/i2p_nude\",\n",
    "    \"logger.json.root\" : \"results/no_attack_esd_nudity_P4D_erase_diff\"\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=no_attack_esd_nudity_classifier_compvis_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_attack_for_nudity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Prompt Attack – CompVis to Diffusers Conversion**\n",
    "\n",
    "If you want to convert the CompVis model into the Diffusers format before running the attack, use the following code. Note: For the conversion to take place, set task.save_diffuser to True and to use the converted model task.sld should be set to None.\n",
    "\n",
    "Note:\n",
    "1.  Enable conversion: When True, the CompVis model is converted to the Diffuser format during the attack process, allowing integration with the Diffusers library for further processing.\n",
    "\n",
    "2. SLD conversion parameters by setting to None. This ensures that no additional SLD modifications interfere with the conversion of the CompVis model to the Diffuser format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.nudity import hard_prompt_esd_nudity_P4D_compvis_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def run_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "        \"task.compvis_ckpt_path\":\"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\",\n",
    "        \"task.compvis_config_path\": erase_diff_train_mu.model_config_path,\n",
    "        \"task.dataset_path\":\"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/outputs/dataset/i2p_nude\",\n",
    "        \"logger.json.root\":\"results/hard_prompt_esd_nudity_P4D_scissorhands\",\n",
    "        \"attacker.no_attack.dataset_path\" : \"/home/ubuntu/Projects/Palistha/unlearn_diff_attack/outputs/dataset/i2p_nude\",\n",
    "        \"task.save_diffuser\": True, # This flag triggers conversion of compvis model to diffuser while performinig attack\n",
    "        \"task.sld\": None, # Set sld to None for conversion of compvis model to diffuser while performinig attack\n",
    "        \"task.model_name\": \"SD-v1-4\"\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=hard_prompt_esd_nudity_P4D_compvis_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_attack_for_nudity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Attack - compvis**\n",
    "\n",
    "Use the following code if you wish to run the No attack using the CompVis model directly (without converting it into Diffusers format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.nudity import no_attack_esd_nudity_classifier_compvis_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def run_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "    \"task.compvis_ckpt_path\" :\"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\",\n",
    "   \"task.compvis_config_path\" : erase_diff_train_mu.model_config_path ,\n",
    "    \"task.dataset_path\" : \"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/outputs/dataset/i2p_nude\",\n",
    "    \"logger.json.root\" : \"results/no_attack_esd_nudity_P4D_erase_diff\"\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=no_attack_esd_nudity_classifier_compvis_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_attack_for_nudity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Attack – CompVis to Diffusers Conversion**\n",
    "\n",
    "If you want to convert the CompVis model into the Diffusers format before running the attack, use the following code. Note: For the conversion to take place, set task.save_diffuser to True and to use the converted model task.sld should be set to None.\n",
    "\n",
    "\n",
    "Note:\n",
    "1.  Enable conversion: When True, the CompVis model is converted to the Diffuser format during the attack process, allowing integration with the Diffusers library for further processing.\n",
    "\n",
    "2. SLD conversion parameters by setting to None. This ensures that no additional SLD modifications interfere with the conversion of the CompVis model to the Diffuser format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mu_attack.configs.nudity import no_attack_esd_nudity_classifier_compvis_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def run_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "    \"task.compvis_ckpt_path\" :\"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\",\n",
    "    \"task.compvis_config_path\" : erase_diff_train_mu.model_config_path ,\n",
    "    \"task.dataset_path\" : \"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/outputs/dataset/i2p_nude\",\n",
    "    \"logger.json.root\" : \"results/hard_prompt_esd_nudity_P4D_erase_diff_compvis_to_diffuser\",\n",
    "    \"task.save_diffuser\": True, #This flag triggers conversion of compvis model to diffuser while performinig attack\n",
    "    \"task.sld\": None, #  sld should be set to None while conversion of compvis model to diffuser while performinig attack\n",
    "    \"task.model_name\": \"SD-v1-4\"\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=no_attack_esd_nudity_classifier_compvis_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_attack_for_nudity()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of MU_attack\n",
    "\n",
    "Calculate the performance of mu_attack using logs and images generated during attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.evaluation import attack_evaluation_config\n",
    "from mu_attack.execs.evaluator import MuAttackEvaluator\n",
    "\n",
    "def main():\n",
    "    config = attack_evaluation_config\n",
    "    config.asr.root = \"results/hard_prompt_esd_nudity_P4D_abstractionism_diffuser/P4d\"\n",
    "    config.asr.root_no_attack = \"results/no_attack_esd_nudity_P4D_erase_diff/NoAttackEsdNudity\"\n",
    "    config.clip.devices = \"0\"\n",
    "    config.clip.image_path = \"results/hard_prompt_esd_nudity_P4D_abstractionism_diffuser/P4d/images\"\n",
    "    config.clip.log_path = \"results/hard_prompt_esd_nudity_P4D_abstractionism_diffuser/P4d/log.json\"\n",
    "    config.fid.ref_batch_path = \"results/no_attack_esd_nudity_P4D_erase_diff/NoAttackEsdNudity/images\"  #to calculate fid score, the genrated image path and ref image path should have ssame number of images.\n",
    "    config.fid.sample_batch_path = \"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/data/i2p/nude\"\n",
    "\n",
    "    # Common output path\n",
    "    config.output_path = \"results/evaluation/results.json\"\n",
    "\n",
    "    evaluator = MuAttackEvaluator(config)\n",
    "\n",
    "    # Run the evaluation (this will run ASR, CLIP, and FID evaluators)\n",
    "    results = evaluator.run()\n",
    "\n",
    "    print(\"Evaluation Results:\",results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mu Defense (AdvUnlean)\n",
    "\n",
    "After performing unlearning and attack, we need to perform adversarial unlearning by integrating a soft prompt attack into the training loop. use the following code snippet for advunlearn.\n",
    "\n",
    "\n",
    "Note: import the model_config_path from the relevant algorithm's configuration module in the mu package\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_defense.algorithms.adv_unlearn.algorithm import AdvUnlearnAlgorithm\n",
    "from mu_defense.algorithms.adv_unlearn.configs import adv_unlearn_config\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def mu_defense():\n",
    "\n",
    "    mu_defense = AdvUnlearnAlgorithm(\n",
    "        config=adv_unlearn_config,\n",
    "        compvis_ckpt_path = \"outputs/erase_diff/finetuned_models/erase_diff_Abstractionism_model.pth\", #path to the finetuned model\n",
    "        attack_step = 2,\n",
    "        backend = \"compvis\",\n",
    "        attack_method = \"fast_at\",\n",
    "        train_method = \"text_encoder_full\",  #training method. check for docs for available train_method \n",
    "        # train_method = \"noxattn\", #training method. check for docs for available train_method \n",
    "        warmup_iter = 1,\n",
    "        iterations = 2,\n",
    "        model_config_path = erase_diff_train_mu.model_config_path  # use same model_config_path for the model you are using\n",
    "\n",
    "    )\n",
    "    mu_defense.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mu_defense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for mu_defense\n",
    "\n",
    "Before proceeding with evaluation, you must generate images using the output from mu_defense.\n",
    "\n",
    "To generate images use the following code snippet:\n",
    "\n",
    "\n",
    "Description of params used:\n",
    "\n",
    "* config: default train config for image generation.\n",
    "* target_ckpt: Model ckpt after running mu_defense (AdvUnleran).\n",
    "* model_config_path: model config path for the model being used for defense.\n",
    "* save_path: output dir to save generated images.\n",
    "* prompts_path: path to the csv with prompts.\n",
    "* num_samples: number of samples to be generated for a prompt.\n",
    "* folder_suffix: suffix for folder name for save path.\n",
    "* devices: devices to be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_defense.algorithms.adv_unlearn.configs import example_image_generator_config\n",
    "from mu_defense.algorithms.adv_unlearn import ImageGenerator\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "\n",
    "def generate_image():\n",
    "    generate_image = ImageGenerator(\n",
    "        config = example_image_generator_config,\n",
    "        target_ckpt = \"outputs/results_with_retaining/nudity/coco_object/pgd/AttackLr_0.001/text_encoder_full/all/prefix_k/AdvUnlearn-nudity-method_text_encoder_full_all-Attack_pgd-Retain_coco_object_iter_1.0-lr_1e-05-AttackLr_0.001-prefix_k_adv_num_1-word_embd-attack_init_latest-attack_step_30-adv_update_1-warmup_iter_200/models/TextEncoder-text_encoder_full-epoch_1.pt\",\n",
    "        model_config_path = erase_diff_train_mu.model_config_path,\n",
    "        save_path = \"outputs/adv_unlearn/models\",\n",
    "        prompts_path = \"data/prompts/sample_prompts.csv\",\n",
    "        num_samples = 1,\n",
    "        folder_suffix = \"imagenette\",\n",
    "        devices = \"0\"\n",
    "\n",
    "    )\n",
    "    generate_image.generate_images()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the images are generated using the finetuned model from defense, you need to evaulate it's performance: \n",
    "\n",
    "Note: Before performing evalaution:\n",
    "1. Download coco 10k dataset from this link : https://drive.google.com/file/d/1Qgm3nNhp6ykamszN_ZvofvuzjryTsPHB/view \n",
    "2. If you want to evaluate just clip score or FID score then mention job as clip or fid accordingly. If you mention nothing then it will calculate both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mu_defense.algorithms.adv_unlearn import MUDefenseEvaluator\n",
    "from mu_defense.algorithms.adv_unlearn.configs import mu_defense_evaluation_config\n",
    "\n",
    "def mu_defense_evaluator():\n",
    "    evaluator = MUDefenseEvaluator(\n",
    "        config = mu_defense_evaluation_config,\n",
    "        gen_imgs_path = \"outputs/adv_unlearn/models_visualizations_imagenette/SD-v1-4/\",\n",
    "        coco_imgs_path = \"coco_dataset/sample/\",\n",
    "        output_path = \"outputs/adv_unlearn/evaluation/\",\n",
    "        devices = \"0\"\n",
    "        # job = \"\"  # \"clip\"  or \"fid\"\n",
    "    )\n",
    "    evaluator.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mu_defense_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UnlearnDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
