{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Unlearning (MU) for Forget me not algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **1: Environment Setup**\n",
    " \n",
    "In this section, we set up our Python environment and install the necessary packages. For reproducibility, itâ€™s best to use a virtual environment.\n",
    "\n",
    "\n",
    "**Prerequisities**\n",
    "\n",
    "Ensure conda is installed on your system. You can install Miniconda or Anaconda:\n",
    "\n",
    "* Miniconda (recommended): https://docs.conda.io/en/latest/miniconda.html\n",
    "\n",
    "* Anaconda: https://www.anaconda.com/products/distribution\n",
    "\n",
    "After installing conda, ensure it is available in your PATH by running. You may require to restart the terminal session:\n",
    "\n",
    "\n",
    "\n",
    "Before installing the unlearn_diff package, follow these steps to set up your environment correctly. These instructions ensure compatibility with the required dependencies, including Python, PyTorch, and ONNX Runtime.\n",
    "\n",
    "\n",
    "**Step-by-Step Setup:**\n",
    "\n",
    "1. Create a Conda Environment Create a new Conda environment named myenv with Python 3.8.5:\n",
    "\n",
    "```bash\n",
    "conda create -n myenv python=3.8.5\n",
    "```\n",
    "\n",
    "2. Activate the Environment Activate the environment to work within it:\n",
    "\n",
    "```bash\n",
    "conda activate myenv\n",
    "```\n",
    "\n",
    "3. Install Core Dependencies Install PyTorch, torchvision, CUDA Toolkit, and ONNX Runtime with specific versions:\n",
    "\n",
    "```bash\n",
    "conda install pytorch==1.11.0 torchvision==0.12.0 cudatoolkit=11.3 onnxruntime==1.16.3 -c pytorch -c conda-forge\n",
    "```\n",
    "\n",
    "4. Install our unlearn_diff Package using pip:\n",
    "\n",
    "```bash\n",
    "pip install unlearn_diff\n",
    "```\n",
    "\n",
    "5. Install Additional Git Dependencies:\n",
    "\n",
    " After installing unlearn_diff, install the following Git-based dependencies in the same Conda environment to ensure full functionality:\n",
    "```bash\n",
    "pip install git+https://github.com/CompVis/taming-transformers.git@master git+https://github.com/openai/CLIP.git@main git+https://github.com/crowsonkb/k-diffusion.git git+https://github.com/cocodataset/panopticapi.git git+https://github.com/Phoveran/fastargs.git@main git+https://github.com/boomb0om/text2image-benchmark\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Downloading the Dataset**\n",
    "\n",
    "After you install the package, you can use the following commands to download.\n",
    "\n",
    "\n",
    "1. quick_canvas:\n",
    "\n",
    "* Sample: \n",
    "\n",
    "```bash \n",
    "     download_data sample quick_canvas\n",
    "```\n",
    "\n",
    "* Full: \n",
    "\n",
    "```bash \n",
    "     download_data full quick_canvas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading sample quick_canvas dataset:\n",
    "\n",
    "!download_data sample quick_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded datasets, verify the Downloaded Files.\n",
    "\n",
    "* ls data/i2p-dataset/sample/\n",
    "\n",
    "* ls -lh ./data/quick-canvas-dataset/sample/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Downloading models**\n",
    "\n",
    "* compvis: \n",
    "\n",
    "```bash \n",
    "     download_model compvis\n",
    "```\n",
    "\n",
    "* diffuser: \n",
    "\n",
    "```bash\n",
    "     download_model diffuser\n",
    "```\n",
    "\n",
    "\n",
    "* Download best.onnx model\n",
    "\n",
    "     ```bash\n",
    "     download_best_onnx\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download compvis model\n",
    "\n",
    "!download_model compvis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download diffuser model\n",
    "\n",
    "!download_model diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!download_best_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Train a Text Inversion**\n",
    "\n",
    "The default configuration for training is provided by forget_me_not_train_ti_mu. You can run the training with the default settings as follows:\n",
    "\n",
    "```python\n",
    "from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm\n",
    "from mu.algorithms.forget_me_not.configs import (\n",
    "    forget_me_not_train_ti_mu,\n",
    ")\n",
    "\n",
    "algorithm = ForgetMeNotAlgorithm(\n",
    "    forget_me_not_train_ti_mu\n",
    ")\n",
    "algorithm.run(train_type=\"train_ti\")\n",
    "```\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "**Overriding the Default Configuration**\n",
    "\n",
    "If you need to override the existing configuration settings, you can specify your custom parameters (such as ckpt_path and raw_dataset_dir) directly when initializing the algorithm. For example:\n",
    "\n",
    "```python\n",
    "from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm\n",
    "from mu.algorithms.forget_me_not.configs import (\n",
    "    forget_me_not_train_ti_mu,\n",
    ")\n",
    "\n",
    "algorithm = ForgetMeNotAlgorithm(\n",
    "    forget_me_not_train_ti_mu,\n",
    "    ckpt_path=\"/home/ubuntu/Projects/UnlearnCanvas/UnlearnCanvas/machine_unlearning/models/diffuser/style50\",\n",
    "    raw_dataset_dir=(\n",
    "        \"/home/ubuntu/Projects/balaram/packaging/data/quick-canvas-dataset/sample\"\n",
    "    ), \n",
    "    steps=10,\n",
    "    use_sample = True\n",
    ")\n",
    "algorithm.run(train_type=\"train_ti\")\n",
    "```\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "Before performing machine unlearning, make sure to generate the safetensors weights file. This file should be produced as part of the unlearning process so that the subsequent machine unlearning step can use these weights. Once generated, the safetensors file will be\n",
    "referenced via the 'ti_weights_path' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate safetensors\n",
    "\n",
    "from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm\n",
    "from mu.algorithms.forget_me_not.configs import (\n",
    "    forget_me_not_train_ti_mu,\n",
    ")\n",
    "\n",
    "algorithm = ForgetMeNotAlgorithm(\n",
    "    forget_me_not_train_ti_mu,\n",
    "    ckpt_path=\"/home/ubuntu/Projects/UnlearnCanvas/UnlearnCanvas/machine_unlearning/models/diffuser/style50\", #replace it with your ckpt path\n",
    "    raw_dataset_dir=(\n",
    "        \"data/quick-canvas-dataset/sample\"\n",
    "    ), \n",
    "    steps=10,\n",
    "    template_name = \"Abstractionism\",\n",
    "    dataset_type = \"unlearncanvas\"\n",
    ")\n",
    "algorithm.run(train_type=\"train_ti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine unlearning using the generated safetensors using unlearn canvas dataset\n",
    "\n",
    "from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm\n",
    "from mu.algorithms.forget_me_not.configs import (\n",
    "    forget_me_not_train_attn_mu,\n",
    ")\n",
    "\n",
    "algorithm = ForgetMeNotAlgorithm(\n",
    "    forget_me_not_train_attn_mu,\n",
    "    ckpt_path=\"/home/ubuntu/Projects/UnlearnCanvas/UnlearnCanvas/machine_unlearning/models/diffuser/style50\", #replace it with your ckpt path\n",
    "    raw_dataset_dir=(\n",
    "        \"data/quick-canvas-dataset/sample\"\n",
    "    ),\n",
    "    steps=10,\n",
    "    ti_weights_path=\"outputs/forget_me_not/ti_models/step_inv_10.safetensors\",\n",
    "    devices = \"0\"\n",
    ")\n",
    "algorithm.run(train_type=\"train_attn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of MU\n",
    "\n",
    "The evaluation framework is used to assess the performance of models after applying machine unlearning.\n",
    "\n",
    "config descriptions:\n",
    "\n",
    "* erase_diff_evaluation_config : default evaluation config for erase_dif\n",
    "* ckpt_path: finetuned model path for erase_diff algorithm. \n",
    "* classifier_ckpt_path: Path to classifier model. Download the classifier ckpt from here: \n",
    "    https://drive.google.com/drive/folders/1AoazlvDgWgc3bAyHDpqlafqltmn4vm61 \n",
    "\n",
    "* refrence_dir: original dataset dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu.algorithms.forget_me_not import ForgetMeNotEvaluator\n",
    "from mu.algorithms.forget_me_not.configs import (\n",
    "    forget_me_not_evaluation_config\n",
    ")\n",
    "from evaluation.metrics.accuracy import accuracy_score\n",
    "from evaluation.metrics.fid import fid_score\n",
    "\n",
    "\n",
    "\n",
    "evaluator = ForgetMeNotEvaluator(\n",
    "    forget_me_not_evaluation_config,\n",
    "    ckpt_path=\"outputs/forget_me_not/finetuned_models/Abstractionism\",\n",
    ")\n",
    "generated_images_path = evaluator.generate_images()\n",
    "\n",
    "reference_image_dir = \"data/quick-canvas-dataset/sample\"\n",
    "\n",
    "accuracy = accuracy_score(gen_image_dir=generated_images_path,\n",
    "                        dataset_type = \"unlearncanvas\",\n",
    "                        classifier_ckpt_path = \"models/classifier_ckpt_path/style50_cls.pth\", #replace it with your ckpt path\n",
    "                        reference_dir=reference_image_dir,\n",
    "                        forget_theme=\"Bricks\",\n",
    "                        seed_list = [\"188\"] )\n",
    "print(accuracy['acc'])\n",
    "print(accuracy['loss'])\n",
    "\n",
    "fid, _ = fid_score(generated_image_dir=generated_images_path,\n",
    "                reference_image_dir=reference_image_dir )\n",
    "\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run Attacks**\n",
    "\n",
    "Before running attacks, download dataset for attack. Run the following command in terminal.\n",
    "\n",
    "<span style=\"color:grey;\"> **generate_attack_dataset --prompts_path data/prompts/nudity_sample.csv --concept i2p_nude --save_path outputs/dataset --num_samples 1** </span>\n",
    "\n",
    "Note: If you want to generate image using full prompt then use `data/prompts/nudity.csv` as prompts_path.\n",
    "\n",
    "Here, prompts_path is the path of csv containing prompt, concept is the name of the concept for organizing output file, save_path is the directory where generated images and metadata will be saved, num_samples is the number of images to generate per prompt.\n",
    "\n",
    "1. **Hard Prompt Attack - Diffuser**\n",
    "\n",
    "Use the following code if you wish to run the hard prompt attack using diffuser model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.nudity import hard_prompt_esd_nudity_P4D_diffusers_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "\n",
    "def run_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "       \"task.diffusers_model_name_or_path\" : \"outputs/forget_me_not/finetuned_models/Abstractionism\", #path to the finetuned model\n",
    "        \"task.dataset_path\" : \"outputs/dataset/i2p_nude\", #generated images path using above given command\n",
    "        \"logger.json.root\" :\"results/hard_prompt_esd_nudity_P4D_abstractionism_diffuser\",\n",
    "        \"attacker.iteration\": 1\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=hard_prompt_esd_nudity_P4D_diffusers_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_attack_for_nudity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Attack - Diffuser**\n",
    "\n",
    "Use the following code if you wish to run the random attack using the Diffuser model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_attack.configs.nudity import no_attack_esd_nudity_classifier_diffusers_config\n",
    "from mu_attack.execs.attack import MUAttack\n",
    "\n",
    "def run_no_attack_for_nudity():\n",
    "\n",
    "    overridable_params = {\n",
    "    \"task.diffusers_model_name_or_path\" :\"outputs/forget_me_not/finetuned_models/Abstractionism\",\n",
    "    \"task.dataset_path\" : \"outputs/dataset/i2p_nude\",\n",
    "    \"logger.json.root\" : \"results/no_attack_esd_nudity_P4D_abstrctionism_diffuser\",\n",
    "    \"attacker.no_attack.dataset_path\" : \"outputs/dataset/i2p_nude\"\n",
    "    }\n",
    "\n",
    "    MUAttack(\n",
    "        config=no_attack_esd_nudity_classifier_diffusers_config,\n",
    "        **overridable_params\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_no_attack_for_nudity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of MU_attack\n",
    "\n",
    "Calculate the performance of mu_attack using logs and images generated during attack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import evaluation metrics from evalaution\n",
    "\n",
    "from evaluation.metrics.asr import asr_score\n",
    "from evaluation.metrics.clip import clip_score\n",
    "from evaluation.metrics.fid import fid_score\n",
    "\n",
    "root = \"results/hard_prompt_esd_nudity_P4D_abstractionism/P4d\"\n",
    "root_no_attack = \"results/no_attack_esd_nudity_P4D_abstrctionism/NoAttackEsdNudity\"\n",
    "devices = \"0\"\n",
    "image_path = \"results/hard_prompt_esd_nudity_P4D_abstractionism/P4d/images\"\n",
    "log_path = \"results/hard_prompt_esd_nudity_P4D_abstractionism/P4d/log.json\"\n",
    "ref_batch_path = \"results/no_attack_esd_nudity_P4D_abstrctionism/NoAttackEsdNudity/images\"\n",
    "sample_batch_path = \"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/data/i2p/nude\"\n",
    "\n",
    "asr_val = asr_score(root, root_no_attack)\n",
    "print(asr_val)\n",
    "\n",
    "clip_val = clip_score(image_path, log_path, devices)\n",
    "print(clip_val)\n",
    "\n",
    "fid_val, _ = fid_score(sample_batch_path,ref_batch_path)\n",
    "print(fid_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mu Defense (AdvUnlean)\n",
    "\n",
    "After performing unlearning and attack, we need to perform adversarial unlearning by integrating a soft prompt attack into the training loop. use the following code snippet for advunlearn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_defense.algorithms.adv_unlearn.algorithm import AdvUnlearnAlgorithm\n",
    "from mu_defense.algorithms.adv_unlearn.configs import adv_unlearn_config\n",
    "\n",
    "\n",
    "def mu_defense():\n",
    "\n",
    "    mu_defense = AdvUnlearnAlgorithm(\n",
    "        config=adv_unlearn_config,\n",
    "        diffusers_model_name_or_path = \"outputs/forget_me_not/finetuned_models/Abstractionism\", #finetuned model\n",
    "        attack_step = 2,\n",
    "        backend = \"diffusers\",\n",
    "        attack_method = \"fast_at\",\n",
    "        # train_method = \"text_encoder_full\",  #training method. check for docs for available train_method \n",
    "        train_method = \"noxattn\", #training method. check for docs for available train_method \n",
    "        warmup_iter = 1,\n",
    "        iterations = 1\n",
    "    )\n",
    "    mu_defense.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mu_defense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for mu_defense\n",
    "\n",
    "\n",
    "Description of params used:\n",
    "\n",
    "* config: default train config for image generation.\n",
    "* target_ckpt: Model ckpt after running mu_defense (AdvUnleran).\n",
    "* save_path: output dir to save generated images.\n",
    "* prompts_path: path to the csv with prompts.\n",
    "* num_samples: number of samples to be generated for a prompt.\n",
    "* folder_suffix: suffix for folder name for save path.\n",
    "* devices: devices to be used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note: Before performing evalaution:\n",
    "1. Download coco 10k dataset from this link : https://drive.google.com/file/d/1Qgm3nNhp6ykamszN_ZvofvuzjryTsPHB/view \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_defense.algorithms.adv_unlearn import MUDefenseEvaluator\n",
    "from mu_defense.algorithms.adv_unlearn.configs import mu_defense_evaluation_config\n",
    "from mu.algorithms.erase_diff.configs import erase_diff_train_mu\n",
    "from evaluation.metrics.clip import clip_score\n",
    "from evaluation.metrics.fid import fid_score\n",
    "\n",
    "target_ckpt = \"outputs/results_with_retaining/nudity/coco_object/pgd/AttackLr_0.001/text_encoder_full/all/prefix_k/AdvUnlearn-nudity-method_text_encoder_full_all-Attack_pgd-Retain_coco_object_iter_1.0-lr_1e-05-AttackLr_0.001-prefix_k_adv_num_1-word_embd-attack_init_latest-attack_step_30-adv_update_1-warmup_iter_200/models/TextEncoder-text_encoder_full-epoch_1.pt\"\n",
    "evaluator = MUDefenseEvaluator(config=mu_defense_evaluation_config,\n",
    "                            target_ckpt = target_ckpt,\n",
    "                            model_config_path = erase_diff_train_mu.model_config_path,\n",
    "                            save_path = \"outputs/adv_unlearn/results\",\n",
    "                            prompts_path = \"data/prompts/sample_prompt.csv\",\n",
    "                            num_samples = 1,\n",
    "                            folder_suffix = \"imagenette\",\n",
    "                            devices = \"0\",)\n",
    "\n",
    "gen_image_path = evaluator.generate_images() #Genereate sample images before evalaution \n",
    "print(gen_image_path)  \n",
    "\n",
    "prompt_path = \"data/prompts/sample_prompt.csv\"\n",
    "ref_image_path = \"/home/ubuntu/Projects/Palistha/msu_unlearningalgorithm/coco_dataset/extracted_files/coco_sample\"\n",
    "device = \"0\"\n",
    "clip_val = clip_score(gen_image_path, prompt_path, device)    \n",
    "print(clip_val)    \n",
    "\n",
    "fid_val, _  = fid_score(gen_image_path, ref_image_path)\n",
    "print(fid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
