<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Usage - Unlearn Diff</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Usage";
        var mkdocs_page_input_path = "unlearn/algorithms/forget_me_not.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> Unlearn Diff
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/unlearn_algorithm_usage/">How to use existing unlearning algorithms</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/how_to_evaluate/">How to evaluate</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Unlearn Algorithms</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" >Concept Ablation</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../concept_ablation/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/concept_ablation/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/concept_ablation/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Erase Diff</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../erase_diff/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/erase_diff/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/erase_diff/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >ESD</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../esd/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/esd/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/esd/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Forget Me Not</a>
    <ul class="current">
                <li class="toctree-l2 current"><a class="reference internal current" href="#">Usage</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#installation">Installation</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#prerequisities">Prerequisities</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#downloading-data-and-models">Downloading data and models.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#run-train">Run Train</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#directory-structure">Directory Structure</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#description-of-arguments-in-train_ti_configyaml">Description of Arguments in train_ti_config.yaml</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#description-of-arguments-in-train_attn_configyaml">Description of Arguments in train_attn_config.yaml</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#key-parameters">Key Parameters</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/forget_me_not/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/forget_me_not/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Saliency Unlearning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../saliency/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/saliency/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/saliency/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Scissor Hands</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../scissorhands/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/scissorhands/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/scissorhands/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Selective Amnesia</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../selective_amnesia/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/selective_amnesia/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/selective_amnesia/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Semi Permeable Membrane</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../semipermeable_membrane/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/semipermeable_membrane/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/semipermeable_membrane/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Unified Concept Editing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../uce/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../examples/uce/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../configs/uce/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Adv Unlearn</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../mu_defense/adv_unlearn/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../mu_defense/config/">Config</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Evaluation</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >Non-Attack evalaution</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >No attack</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/attack/no_attack/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/configs/no_attack/">Config</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Robustness Eval UnlearnDiffAtk</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Hard Prompt</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/attack/hard_prompt/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/configs/hard_prompt/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Random</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/attack/random/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/configs/random/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Seed Search</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/attack/seed_search/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/configs/seed_search/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Text Grad</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/attack/text_grad/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../../mu_attack/configs/text_grad/">Config</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Utility Eval</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Concept Ablation</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/concept_ablation/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Erase Diff</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/erase_diff/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >ESD</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/esd/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Forget Me Not</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/forget_me_not/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Saliency Unlearning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/saliency/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Scissor Hands</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/scissorhands/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Semi Permeable Membrane</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/semipermeable_membrane/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Unified Concept Editing</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/uce/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >MU_Defense</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/adv_unlearn_evaluation/">Usage</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">Unlearn Diff</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Unlearn Algorithms</li>
          <li class="breadcrumb-item">Forget Me Not</li>
      <li class="breadcrumb-item active">Usage</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="forget-me-not-algorithm-for-machine-unlearning">Forget Me Not Algorithm for Machine Unlearning</h1>
<p>This repository provides an implementation of the erase diff algorithm for machine unlearning in Stable Diffusion models. The Forget Me Not algorithm allows you to remove specific concepts or styles from a pre-trained model without retraining it from scratch.</p>
<h2 id="installation">Installation</h2>
<h3 id="prerequisities">Prerequisities</h3>
<p>Ensure <code>conda</code> is installed on your system. You can install Miniconda or Anaconda:</p>
<ul>
<li><strong>Miniconda</strong> (recommended): <a href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a></li>
<li><strong>Anaconda</strong>: <a href="https://www.anaconda.com/products/distribution">https://www.anaconda.com/products/distribution</a></li>
</ul>
<p>After installing <code>conda</code>, ensure it is available in your PATH by running. You may require to restart the terminal session:</p>
<pre><code class="language-bash">conda --version
</code></pre>
<p><strong>Step-by-Step Setup:</strong></p>
<p>Step 1. Create a Conda Environment Create a new Conda environment named myenv with Python 3.8.5:</p>
<pre><code class="language-bash">conda create -n myenv python=3.8.5
</code></pre>
<p>Step 2. Activate the Environment Activate the environment to work within it:</p>
<pre><code class="language-bash">conda activate myenv
</code></pre>
<p>Step 3. Install Core Dependencies Install PyTorch, torchvision, CUDA Toolkit, and ONNX Runtime with specific versions:</p>
<pre><code class="language-bash">conda install pytorch==1.11.0 torchvision==0.12.0 cudatoolkit=11.3 onnxruntime==1.16.3 -c pytorch -c conda-forge
</code></pre>
<p>Step 4. Install our unlearn_diff Package using pip:</p>
<pre><code class="language-bash">pip install unlearn_diff
</code></pre>
<p>Step 5. Install Additional Git Dependencies:</p>
<p>After installing unlearn_diff, install the following Git-based dependencies in the same Conda environment to ensure full functionality:</p>
<pre><code class="language-bash">pip install git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/openai/CLIP.git@main#egg=clip
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/crowsonkb/k-diffusion.git
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/cocodataset/panopticapi.git
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/Phoveran/fastargs.git@main#egg=fastargs
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/boomb0om/text2image-benchmark
</code></pre>
<h3 id="downloading-data-and-models">Downloading data and models.</h3>
<p>After you install the package, you can use the following commands to download.</p>
<ol>
<li><strong>Dataset</strong>:</li>
<li><strong>i2p</strong>:<ul>
<li><strong>Sample</strong>:
 <code>download_data sample i2p</code></li>
<li><strong>Full</strong>:
 <code>download_data full i2p</code></li>
</ul>
</li>
<li>
<p><strong>quick_canvas</strong>:</p>
<ul>
<li><strong>Sample</strong>:
 <code>download_data sample quick_canvas</code></li>
<li><strong>Full</strong>:
 <code>download_data full quick_canvas</code></li>
</ul>
</li>
<li>
<p><strong>Model</strong>:</p>
</li>
<li><strong>compvis</strong>:
    <code>download_model compvis</code></li>
<li><strong>diffuser</strong>:
    <code>download_model diffuser</code></li>
<li>
<p>Download best.onnx file</p>
<p><code>download_best_onnx</code></p>
</li>
</ol>
<p><strong>Verify the Downloaded Files</strong></p>
<p>After downloading, verify that the datasets have been correctly extracted:</p>
<pre><code class="language-bash">ls -lh ./data/i2p-dataset/sample/
ls -lh ./data/quick-canvas-dataset/sample/
</code></pre>
<hr />
<h2 id="run-train">Run Train</h2>
<p>Create a file, eg, <code>my_trainer.py</code> and use examples and modify your configs to run the file.  </p>
<ol>
<li><strong>Train a Text Inversion using quick canvas dataset</strong></li>
</ol>
<p>Before finetuning the model you need to generate safetensors.</p>
<pre><code class="language-python">
from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_ti_mu,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_ti_mu,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir=(
        &quot;data/quick-canvas-dataset/sample&quot;
    ), 
    steps=10,
    template_name = &quot;Abstractionism&quot;, #concept to erase
    dataset_type = &quot;unlearncanvas&quot; ,
    use_sample = True, #train on sample dataset
    output_dir = &quot;outputs/forget_me_not/finetuned_models&quot; #output dir to save finetuned models
)
algorithm.run(train_type=&quot;train_ti&quot;)
</code></pre>
<p><strong>Running the Script in Offline Mode</strong></p>
<pre><code class="language-bash">WANDB_MODE=offline python my_trainer_ti.py
</code></pre>
<ol>
<li><strong>Perform Unlearning using quick canvas dataset</strong></li>
</ol>
<p>Before running the <code>train_attn</code> script, update the <code>ti_weights_path</code> parameter in the configuration file to point to the output generated from the Text Inversion (train_ti.py) stage</p>
<pre><code class="language-python">from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_attn_mu,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_attn_mu,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir=(
        &quot;data/quick-canvas-dataset/sample&quot;
    ),
    steps=10,
    ti_weights_path=&quot;outputs/forget_me_not/finetuned_models/Abstractionism/step_inv_10.safetensors&quot;,
    template_name = &quot;Abstractionism&quot;, #concept to erase
    dataset_type = &quot;unlearncanvas&quot; ,
    use_sample = True, #train on sample dataset
    output_dir = &quot;outputs/forget_me_not/finetuned_models&quot; #output dir to save finetuned models
)
algorithm.run(train_type=&quot;train_attn&quot;)
</code></pre>
<ol>
<li><strong>Train a Text Inversion using i2p dataset</strong></li>
</ol>
<p>Before finetuning the model you need to generate safetensors.</p>
<pre><code class="language-python">
from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_ti_i2p,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_ti_i2p,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir = &quot;data/i2p-dataset/sample&quot;,
    steps=10,
    template_name = &quot;self-harm&quot;, #concept to erase
    dataset_type = &quot;i2p&quot; ,
    use_sample = True, #train on sample dataset
    output_dir = &quot;outputs/forget_me_not/finetuned_models&quot; #output dir to save finetuned models
)
algorithm.run(train_type=&quot;train_ti&quot;)
</code></pre>
<p><strong>Running the Script in Offline Mode</strong></p>
<pre><code class="language-bash">WANDB_MODE=offline python my_trainer_ti.py
</code></pre>
<ol>
<li><strong>Perform Unlearning</strong></li>
</ol>
<p>Before running the <code>train_attn</code> script, update the <code>ti_weights_path</code> parameter in the configuration file to point to the output generated from the Text Inversion (train_ti.py) stage</p>
<pre><code class="language-python">from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_attn_mu,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_attn_mu,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir=(
        &quot;data/quick-canvas-dataset/sample&quot;
    ),
    steps=10,
    ti_weights_path=&quot;outputs/forget_me_not/finetuned_models/Abstractionism/step_inv_10.safetensors&quot;,
    use_sample = True, #train on sample dataset
    output_dir = &quot;outputs/forget_me_not/finetuned_models&quot; ,#output dir to save finetuned models
    template_name = &quot;self-harm&quot;, #concept to erase
    dataset_type = &quot;i2p&quot; ,
)
algorithm.run(train_type=&quot;train_attn&quot;)
</code></pre>
<p><strong>Run on your won dataset</strong></p>
<p><strong>Step-1: Generate your own dataset</strong></p>
<pre><code class="language-bash">generate_images_for_prompts --model_path models/diffuser/style50 --csv_path data/prompts/generic_data.csv
</code></pre>
<p>Note:</p>
<ul>
<li>
<p>generate_images_for_prompts: This command invokes the image generation script. It uses a diffusion model to generate images based on textual prompts.</p>
</li>
<li>
<p>--model_path: Specifies the path to the diffusion model to be used for image generation. In this example, the model is located at models/diffuser/style50.</p>
</li>
<li>
<p>--csv_path: Provides the path to a CSV file containing the prompts. Each prompt in this CSV will be used to generate an image, allowing you to build a dataset tailored to your needs.</p>
</li>
</ul>
<p><strong>Step-2: Train  text inversion on your own dataset</strong></p>
<pre><code class="language-python">from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_ti_mu,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_ti_mu,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir=(
        &quot;data/generic&quot; #replace with your own generated path
    ), 
    steps=10,
    template_name = &quot;self-harm&quot;,
    dataset_type = &quot;generic&quot;
)
algorithm.run(train_type=&quot;train_ti&quot;)
</code></pre>
<p><strong>Perform Unlearning on your own dataset</strong></p>
<pre><code class="language-python">from mu.algorithms.forget_me_not.algorithm import ForgetMeNotAlgorithm
from mu.algorithms.forget_me_not.configs import (
    forget_me_not_train_attn_mu,
)

algorithm = ForgetMeNotAlgorithm(
    forget_me_not_train_attn_mu,
    ckpt_path=&quot;models/diffuser/style50&quot;,
    raw_dataset_dir=(
        &quot;data/generic&quot; #replace with your own generated path
    ),
    steps=10,
    ti_weights_path=&quot;outputs/forget_me_not/ti_models/step_inv_10.safetensors&quot;,
    template_name = &quot;self-harm&quot;,
    dataset_type = &quot;generic&quot;
)
algorithm.run(train_type=&quot;train_attn&quot;)
</code></pre>
<p><strong>Running the Script in Offline Mode</strong></p>
<pre><code class="language-bash">WANDB_MODE=offline python my_trainer_attn.py
</code></pre>
<p><strong>How It Works</strong> 
* Default Values: The script first loads default values from the train config file as in configs section.</p>
<ul>
<li>
<p>Parameter Overrides: Any parameters passed directly to the algorithm, overrides these configs.</p>
</li>
<li>
<p>Final Configuration: The script merges the configs and convert them into dictionary to proceed with the training. </p>
</li>
</ul>
<h2 id="directory-structure">Directory Structure</h2>
<ul>
<li><code>algorithm.py</code>: Implementation of the Forget Me NotAlgorithm class.</li>
<li><code>configs/</code>: Contains configuration files for training and generation.</li>
<li><code>model.py</code>: Implementation of the Forget Me NotModel class.</li>
<li><code>scripts/train.py</code>: Script to train the Forget Me Not algorithm.</li>
<li><code>trainer.py</code>: Implementation of the Forget Me NotTrainer class.</li>
<li><code>utils.py</code>: Utility functions used in the project.</li>
<li><code>data_handler.py</code> : Implementation of DataHandler class</li>
</ul>
<hr />
<p><strong>This method involves two stages:</strong></p>
<ol>
<li>
<p><strong>Train a Text Inversion</strong>: The first stage involves training a Text Inversion. Refer to the script <a href="mu/algorithms/forget_me_not/scripts/train_ti.py"><code>train_ti.py</code></a> for details and implementation. It uses <code>train_ti_config.yaml</code> as config file.</p>
</li>
<li>
<p><strong>Perform Unlearning</strong>: The second stage uses the outputs from the first stage to perform unlearning. Refer to the script <a href="mu/algorithms/forget_me_not/scripts/train_attn.py"><code>train_attn.py</code></a> for details and implementation. It uses <code>train_attn_config.yaml</code> as config file.</p>
</li>
</ol>
<h3 id="description-of-arguments-in-train_ti_configyaml">Description of Arguments in train_ti_config.yaml</h3>
<p><strong>Pretrained Model</strong></p>
<ul>
<li><strong>ckpt_path</strong>: File path to the pretrained model's checkpoint file.</li>
</ul>
<p><strong>Dataset</strong></p>
<ul>
<li><strong>raw_dataset_dir</strong>: Directory containing the original dataset organized by themes and classes.</li>
<li><strong>processed_dataset_dir</strong>: Directory where the processed datasets will be saved.</li>
<li><strong>dataset_type</strong>: Type of dataset to use (e.g., <code>unlearncanvas</code>). Use <code>generic</code> as type if you want to use your own dataset. Valid choices are <code>unlearncanvas</code>, <code>i2p</code> and <code>generic</code>.</li>
<li><strong>template</strong>: Type of template to use (e.g., <code>style</code>).</li>
<li><strong>template_name</strong>: Name of the template, defining the style or theme (e.g., <code>Abstractionism</code>).</li>
<li><strong>use_sample</strong>: Boolean indicating whether to use the sample dataset for training.</li>
</ul>
<p><strong>Training Configuration</strong></p>
<ul>
<li><strong>initializer_tokens</strong>: Tokens used to initialize the training process, referencing the template name.</li>
<li><strong>steps</strong>: Number of training steps.</li>
<li><strong>lr</strong>: Learning rate for the training optimizer.</li>
<li><strong>weight_decay_ti</strong>: Weight decay for Text Inversion training.</li>
<li><strong>seed</strong>: Random seed for reproducibility.</li>
<li><strong>placeholder_tokens</strong>: Tokens used as placeholders during training.</li>
<li><strong>placeholder_token_at_data</strong>: Placeholders used in the dataset for Text Inversion training.</li>
<li><strong>gradient_checkpointing</strong>: Boolean to enable or disable gradient checkpointing.</li>
<li><strong>scale_lr</strong>: Boolean indicating whether to scale the learning rate based on batch size.</li>
<li><strong>gradient_accumulation_steps</strong>: Number of steps to accumulate gradients before updating weights.</li>
<li><strong>train_batch_size</strong>: Batch size for training.</li>
<li><strong>lr_warmup_steps</strong>: Number of steps for linear warmup of the learning rate.</li>
</ul>
<p><strong>Output Configuration</strong></p>
<ul>
<li><strong>output_dir</strong>: Directory path to save training results, including models and logs.</li>
</ul>
<p><strong>Device Configuration</strong></p>
<ul>
<li><strong>devices</strong>: CUDA devices to train on (comma-separated).</li>
</ul>
<h3 id="description-of-arguments-in-train_attn_configyaml">Description of Arguments in train_attn_config.yaml</h3>
<h3 id="key-parameters">Key Parameters</h3>
<p><strong>Pretrained Model</strong></p>
<ul>
<li><strong>ckpt_path</strong>: File path to the pretrained model's checkpoint file.</li>
</ul>
<p><strong>Dataset</strong></p>
<ul>
<li><strong>raw_dataset_dir</strong>: Directory containing the original dataset organized by themes and classes.</li>
<li><strong>processed_dataset_dir</strong>: Directory where the processed datasets will be saved.</li>
<li><strong>dataset_type</strong>: Type of dataset to use (e.g., <code>unlearncanvas</code>).</li>
<li><strong>template</strong>: Type of template to use (e.g., <code>style</code>).</li>
<li><strong>template_name</strong>: Name of the template, defining the style or theme (e.g., <code>Abstractionism</code>).</li>
<li><strong>use_sample</strong>: Boolean indicating whether to use the sample dataset for training.</li>
</ul>
<p><strong>Text Inversion</strong></p>
<ul>
<li><strong>use_ti</strong>: Boolean indicating whether to use Text Inversion weights.</li>
<li><strong>ti_weights_path</strong>: File path to the Text Inversion model weights.</li>
</ul>
<p><strong>Tokens</strong></p>
<ul>
<li><strong>initializer_tokens</strong>: Tokens used to initialize the training process, referencing the template name.</li>
<li><strong>placeholder_tokens</strong>: Tokens used as placeholders during training.</li>
</ul>
<p><strong>Training Configuration</strong></p>
<ul>
<li><strong>mixed_precision</strong>: Precision type to use during training (e.g., <code>fp16</code> or <code>fp32</code>).</li>
<li><strong>gradient_accumulation_steps</strong>: Number of steps to accumulate gradients before updating weights.</li>
<li><strong>train_text_encoder</strong>: Boolean to enable or disable training of the text encoder.</li>
<li><strong>enable_xformers_memory_efficient_attention</strong>: Boolean to enable memory-efficient attention mechanisms.</li>
<li><strong>gradient_checkpointing</strong>: Boolean to enable or disable gradient checkpointing.</li>
<li><strong>allow_tf32</strong>: Boolean to allow TensorFloat-32 computation for faster training.</li>
<li><strong>scale_lr</strong>: Boolean indicating whether to scale the learning rate based on batch size.</li>
<li><strong>train_batch_size</strong>: Batch size for training.</li>
<li><strong>use_8bit_adam</strong>: Boolean to enable or disable 8-bit Adam optimizer.</li>
<li><strong>adam_beta1</strong>: Beta1 parameter for the Adam optimizer.</li>
<li><strong>adam_beta2</strong>: Beta2 parameter for the Adam optimizer.</li>
<li><strong>adam_weight_decay</strong>: Weight decay for the Adam optimizer.</li>
<li><strong>adam_epsilon</strong>: Epsilon value for the Adam optimizer.</li>
<li><strong>size</strong>: Image resolution size for training.</li>
<li><strong>with_prior_preservation</strong>: Boolean indicating whether to use prior preservation during training.</li>
<li><strong>num_train_epochs</strong>: Number of training epochs.</li>
<li><strong>lr_warmup_steps</strong>: Number of steps for linear warmup of the learning rate.</li>
<li><strong>lr_num_cycles</strong>: Number of cycles for learning rate scheduling.</li>
<li><strong>lr_power</strong>: Exponent to control the shape of the learning rate curve.</li>
<li><strong>max-steps</strong>: Maximum number of training steps.</li>
<li><strong>no_real_image</strong>: Boolean to skip using real images in training.</li>
<li><strong>max_grad_norm</strong>: Maximum norm for gradient clipping.</li>
<li><strong>checkpointing_steps</strong>: Number of steps between model checkpoints.</li>
<li><strong>set_grads_to_none</strong>: Boolean to set gradients to None instead of zeroing them out.</li>
<li><strong>lr</strong>: Learning rate for the training optimizer.</li>
</ul>
<p><strong>Output Configuration</strong></p>
<ul>
<li><strong>output_dir</strong>: Directory path to save training results, including models and logs.</li>
</ul>
<p><strong>Device Configuration</strong></p>
<ul>
<li><strong>devices</strong>: CUDA devices to train on (comma-separated).</li>
</ul>
<p><strong>Miscellaneous</strong></p>
<ul>
<li><strong>only-xa</strong>: Boolean to enable additional configurations specific to the XA pipeline.</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../configs/esd/" class="btn btn-neutral float-left" title="Configs"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../examples/forget_me_not/" class="btn btn-neutral float-right" title="Examples">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../configs/esd/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../examples/forget_me_not/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
