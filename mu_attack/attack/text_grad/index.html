<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Usage - Unlearn Diff</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Usage";
        var mkdocs_page_input_path = "mu_attack/attack/text_grad.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> Unlearn Diff
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Usage</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/unlearn_algorithm_usage/">How to use existing unlearning algorithms</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../usage/how_to_evaluate/">How to evaluate</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Unlearn Algorithms</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" >Concept Ablation</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/concept_ablation/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/concept_ablation/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/concept_ablation/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Erase Diff</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/erase_diff/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/erase_diff/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/erase_diff/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >ESD</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/esd/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/esd/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/esd/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Forget Me Not</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/forget_me_not/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/forget_me_not/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/forget_me_not/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Saliency Unlearning</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/saliency/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/saliency/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/saliency/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Scissor Hands</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/scissorhands/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/scissorhands/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/scissorhands/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Selective Amnesia</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/selective_amnesia/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/selective_amnesia/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/selective_amnesia/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Semi Permeable Membrane</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/semipermeable_membrane/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/semipermeable_membrane/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/semipermeable_membrane/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Unified Concept Editing</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/algorithms/uce/">Usage</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/examples/uce/">Examples</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../../unlearn/configs/uce/">Configs</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Adv Unlearn</a>
    <ul>
                <li class="toctree-l2"><a class="" href="../../../mu_defense/adv_unlearn.md">Usage</a>
                </li>
                <li class="toctree-l2"><a class="" href="../../../mu_defense/config.md">Config</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Evaluation</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" >Non-Attack evalaution</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >No attack</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../no_attack/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../configs/no_attack/">Config</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" >Robustness Eval UnlearnDiffAtk</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" >Hard Prompt</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../hard_prompt/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../configs/hard_prompt/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Random</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../random/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../configs/random/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Seed Search</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../seed_search/">Usage</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../configs/seed_search/">Config</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" >Text Grad</a>
    <ul class="current">
                <li class="toctree-l3 current"><a class="reference internal current" href="#">Usage</a>
    <ul class="current">
    </ul>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../configs/text_grad/">Config</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Utility Eval</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" >Concept Ablation</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/concept_ablation/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Erase Diff</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/erase_diff/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >ESD</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/esd/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Forget Me Not</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/forget_me_not/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Saliency Unlearning</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/saliency/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Scissor Hands</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/scissorhands/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Semi Permeable Membrane</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/semipermeable_membrane/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >Unified Concept Editing</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../../evaluation/uce/">Usage</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" >MU_Defense</a>
    <ul>
                <li class="toctree-l3"><a class="" href="../../../mu_defense/evaluation.md">Usage</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">Unlearn Diff</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Evaluation</li>
          <li class="breadcrumb-item">Robustness Eval UnlearnDiffAtk</li>
          <li class="breadcrumb-item">Text Grad</li>
      <li class="breadcrumb-item active">Usage</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h2 id="unlearndiffattak">UnlearnDiffAttak</h2>
<p>This repository contains the implementation of UnlearnDiffAttack for text grad, a framework for evaluating the robustness of safety-driven unlearned Models using adversarial prompts.</p>
<h2 id="usage">Usage</h2>
<p>This section contains the usage guide for the package.</p>
<h3 id="installation">Installation</h3>
<h4 id="prerequisities">Prerequisities</h4>
<p>Ensure <code>conda</code> is installed on your system. You can install Miniconda or Anaconda:</p>
<ul>
<li><strong>Miniconda</strong> (recommended): <a href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a></li>
<li><strong>Anaconda</strong>: <a href="https://www.anaconda.com/products/distribution">https://www.anaconda.com/products/distribution</a></li>
</ul>
<p>After installing <code>conda</code>, ensure it is available in your PATH by running. You may require to restart the terminal session:</p>
<p>Before installing the unlearn_diff package, follow these steps to set up your environment correctly. These instructions ensure compatibility with the required dependencies, including Python, PyTorch, and ONNX Runtime.</p>
<p><strong>Step-by-Step Setup:</strong></p>
<p>Step 1. Create a Conda Environment Create a new Conda environment named myenv with Python 3.8.5:</p>
<pre><code class="language-bash">conda create -n myenv python=3.8.5
</code></pre>
<p>Step 2. Activate the Environment Activate the environment to work within it:</p>
<pre><code class="language-bash">conda activate myenv
</code></pre>
<p>Step 3. Install Core Dependencies Install PyTorch, torchvision, CUDA Toolkit, and ONNX Runtime with specific versions:</p>
<pre><code class="language-bash">conda install pytorch==1.11.0 torchvision==0.12.0 cudatoolkit=11.3 onnxruntime==1.16.3 -c pytorch -c conda-forge
</code></pre>
<p>Step 4. Install our unlearn_diff Package using pip:</p>
<pre><code class="language-bash">pip install unlearn_diff
</code></pre>
<p>Step 5. Install Additional Git Dependencies:</p>
<p>After installing unlearn_diff, install the following Git-based dependencies in the same Conda environment to ensure full functionality:</p>
<pre><code class="language-bash">pip install git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/openai/CLIP.git@main#egg=clip
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/crowsonkb/k-diffusion.git
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/cocodataset/panopticapi.git
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/Phoveran/fastargs.git@main#egg=fastargs
</code></pre>
<pre><code class="language-bash">pip install git+https://github.com/boomb0om/text2image-benchmark
</code></pre>
<h3 id="downloading-bestonnx-model">Downloading best.onnx model.</h3>
<p>After you install the package, you can use the following commands to download. If you have already downloaded then skip this step.</p>
<pre><code>```bash
download_best_onnx
```
</code></pre>
<h3 id="generate-dataset">Generate Dataset</h3>
<p>Before running attacks you need to generate dataset. Run the following command into the terminal.</p>
<pre><code class="language-bash">generate_attack_dataset --prompts_path data/prompts/nudity_sample.csv --concept i2p_nude --save_path outputs/dataset --num_samples 1
</code></pre>
<p>Note: If you want to generate image using full prompt then use <code>data/prompts/nudity.csv</code> as prompts_path.</p>
<h3 id="run-attack">Run Attack</h3>
<ol>
<li><strong>Text Grad Attack - compvis</strong></li>
</ol>
<p>Use the following code if you wish to run the seed search attack using the CompVis model directly (without converting it into Diffusers format):</p>
<pre><code class="language-python">from mu_attack.configs.nudity import text_grad_esd_nudity_classifier_compvis_config
from mu_attack.execs.attack import MUAttack
from mu.algorithms.scissorhands.configs import scissorhands_train_mu

def run_attack_for_nudity():

    overridable_params = {
    &quot;task.compvis_ckpt_path&quot; :&quot;/home/ubuntu/Projects/dipesh/unlearn_diff/outputs/scissorhands/finetuned_models/scissorhands_Abstractionism_model.pth&quot;,
    &quot;task.compvis_config_path&quot; : scissorhands_train_mu.model_config_path,
    &quot;task.dataset_path&quot; : &quot;/home/ubuntu/Projects/Palistha/unlearn_diff_attack/outputs/dataset/i2p_nude&quot;,
    &quot;attacker.text_grad.lr&quot;: 0.02,
    &quot;logger.json.root&quot; : &quot;results/seed_search_esd_nudity_P4D_scissorhands&quot;

    }

    MUAttack(
        config=text_grad_esd_nudity_classifier_compvis_config,
        **overridable_params
    )

if __name__ == &quot;__main__&quot;:
    run_attack_for_nudity()
</code></pre>
<ol>
<li><strong>Text Grad Attack – CompVis to Diffusers Conversion</strong></li>
</ol>
<p>If you want to convert the CompVis model into the Diffusers format before running the attack, use the following code. Note: For the conversion to take place, set task.save_diffuser to True and to use the converted model task.sld should be set to None.</p>
<pre><code class="language-python">from mu_attack.configs.nudity import text_grad_esd_nudity_classifier_compvis_config
from mu_attack.execs.attack import MUAttack
from mu.algorithms.scissorhands.configs import scissorhands_train_mu

def run_attack_for_nudity():

    overridable_params = {
        &quot;task.compvis_ckpt_path&quot; :&quot;/home/ubuntu/Projects/dipesh/unlearn_diff/outputs/scissorhands/finetuned_models/scissorhands_Abstractionism_model.pth&quot;,
        &quot;task.compvis_config_path&quot; : scissorhands_train_mu.model_config_path,
        &quot;task.dataset_path&quot; : &quot;/home/ubuntu/Projects/Palistha/unlearn_diff_attack/outputs/dataset/i2p_nude&quot;,
        &quot;attacker.text_grad.lr&quot;: 0.02,
        &quot;logger.json.root&quot; : &quot;results/seed_search_esd_nudity_P4D_scissorhands&quot;,
        &quot;task.save_diffuser&quot;: True, # This flag triggers conversion
        &quot;task.sld&quot;: None, # Set sld to None for conversion
        &quot;task.model_name&quot;: &quot;SD-v1-4&quot;
    }

    MUAttack(
        config=text_grad_esd_nudity_classifier_compvis_config,
        **overridable_params
    )

if __name__ == &quot;__main__&quot;:
    run_attack_for_nudity()
</code></pre>
<p><strong>For Conversion:</strong></p>
<p>When converting a CompVis model to the Diffusers format, ensure that task.save_diffuser is set to True and task.sld is set to None. This instructs the pipeline to perform the conversion during initialization and then load the converted checkpoint.</p>
<p><strong>Code Explanation &amp; Important Notes</strong></p>
<ol>
<li>
<p>from mu_attack.configs.nudity import text_grad_esd_nudity_P4D_compvis_config
→ This imports the predefined text grad Attack configuration for nudity unlearning in the CompVis model. It sets up the attack parameters and methodologies.</p>
</li>
<li>
<p>from mu.algorithms.scissorhands.configs import scissorhands_train_mu
→ Imports the Scissorhands model configuration, required to set the task.compvis_config_path parameter correctly.</p>
</li>
</ol>
<p><strong>Overriding Parameters in JSON Configuration</strong></p>
<ul>
<li>
<p>The overridable_params dictionary allows dynamic modification of parameters defined in the JSON configuration.</p>
</li>
<li>
<p>This enables users to override default values by passing them as arguments.</p>
</li>
</ul>
<p><strong>Example usage</strong></p>
<pre><code class="language-python">overridable_params = {
    &quot;task.compvis_ckpt_path&quot;: &quot;outputs/scissorhands/finetuned_models/scissorhands_Abstractionism_model.pth&quot;,
    &quot;task.compvis_config_path&quot;: scissorhands_train_mu.model_config_path,  # Overrides model config
    &quot;task.dataset_path&quot;: &quot;outputs/dataset/i2p_nude&quot;,  # Overrides dataset path
    &quot;logger.json.root&quot;: &quot;results/seed_search_esd_nudity_P4D_scissorhands&quot;,  # Overrides logging path
    &quot;attacker.k&quot; = 3,
    &quot;attacker.no_attack.dataset_path&quot; = &quot;path/to/dataset&quot; #overrides the datset path for no attack
}

</code></pre>
<ol>
<li><strong>Text Grad Attack - diffuser</strong></li>
</ol>
<pre><code class="language-python">from mu_attack.configs.nudity import text_grad_esd_nudity_classifier_diffuser_config
from mu_attack.execs.attack import MUAttack

def run_attack_for_nudity():

    overridable_params = {
    &quot;task.diffusers_model_name_or_path&quot; : &quot;outputs/forget_me_not/finetuned_models/Abstractionism&quot;,
    &quot;task.dataset_path&quot; : &quot;outputs/dataset/i2p_nude&quot;,
    &quot;logger.json.root&quot; : &quot;results/random_esd_nudity_diffuser_uce&quot;

    }

    MUAttack(
        config=text_grad_esd_nudity_classifier_diffuser_config,
        **overridable_params
    )

if __name__ == &quot;__main__&quot;:
    run_attack_for_nudity()
</code></pre>
<p><strong>Code Explanation &amp; Important Notes</strong></p>
<ol>
<li>from mu_attack.configs.nudity import text_grad_esd_nudity_P4D_diffusers_config
→ This imports the predefined Text Grad Attack configuration for nudity unlearning in the diffusers model. It sets up the attack parameters and methodologies.</li>
</ol>
<h3 id="description-of-fields-in-config-json-file">Description of fields in config json file</h3>
<ol>
<li>overall</li>
</ol>
<p>This section defines the high-level configuration for the attack.</p>
<ul>
<li>
<p>task : The name of the task being performed.</p>
<p>Type: str
Example: classifer</p>
</li>
<li>
<p>attacker: Specifies the attack type.</p>
<p>Type: str
Example: text_grad</p>
</li>
<li>
<p>logger: Defines the logging mechanism.</p>
<p>Type: str
Example: JSON</p>
</li>
<li>
<p>resume: Option to resume from previous checkpoint.</p>
</li>
<li>
<p>task</p>
</li>
<li>
<p>concept: The concept targeted by the attack.</p>
<p>Type: str
Example: nudity</p>
</li>
<li>
<p>diffusers_model_name_or_path: Path to the pre-trained checkpoint of the diffuser model. (For diffuser)</p>
<p>Type: str
Example: "outputs/semipermeable_membrane/finetuned_models/"</p>
</li>
<li>
<p>target_ckpt: Path to the target model checkpoint used in the attack.  (For diffuser)</p>
<p>Type: str
Example: "files/pretrained/SD-1-4/ESD_ckpt/Nudity-ESDx1-UNET-SD.pt"</p>
</li>
<li>
<p>compvis_ckpt_path: Path to the pre-trained checkpoint of the CompVis model. (For compvis)</p>
<p>Type: str
Example: "outputs/scissorhands/finetuned_models/scissorhands_Abstractionism_model.pth"</p>
</li>
<li>
<p>compvis_config_path: Path to the configuration file for the CompVis model. (For compvis)</p>
<p>Type: str
Example: "configs/scissorhands/model_config.yaml"</p>
</li>
<li>
<p>cache_path: Directory to cache intermediate results.</p>
<p>Type: str
Example: ".cache"</p>
</li>
<li>
<p>dataset_path: Path to the dataset used for the attack.</p>
<p>Type: str
Example: "outputs/dataset/i2p_nude"</p>
</li>
<li>
<p>criterion: The loss function or criterion used during the attack.</p>
<p>Type: str
Example: "l2"</p>
</li>
<li>
<p>classifier_dir: Directory for the classifier, if applicable. null if not used.
    Type: str
    Example: "/path/classifier_dir"</p>
</li>
<li>
<p>sampling_step_num: Number of sampling steps during the attack.</p>
<p>Type: int
Example: 1</p>
</li>
<li>
<p>sld: Strength of latent disentanglement.</p>
<p>Type: str
Example: "weak" </p>
</li>
<li>
<p>sld_concept: Concept tied to latent disentanglement.</p>
<p>Type: str
Example: "nudity"</p>
</li>
<li>
<p>negative_prompt: The negative prompt used to steer the generation. </p>
<p>Type: str
Example: "sth"</p>
</li>
<li>
<p>model_name: Name of the model. The model_name parameter determines which base Stable Diffusion model is used by the pipeline.</p>
<p>Type: str
Example: "SD-v1-4"
Choices: "SD-v1-4", "SD-V2", "SD-V2-1"</p>
</li>
<li>
<p>save_diffuser: A Boolean flag that determines whether the CompVis model should be converted into the Diffusers format before being used.</p>
<p>Type: str
Example: True</p>
<p>Behavior:
* If set to True, the pipeline will perform a conversion of the CompVis model into the Diffusers format and then load the converted checkpoint.</p>
<ul>
<li>If set to False, the conversion is skipped and the model remains in its original CompVis format for use and uses compvis based implementation.</li>
</ul>
</li>
<li>
<p>converted_model_folder_path: Folder path to save the converted compvis model to diffuser.</p>
<p>Type: str
Example: "outputs"</p>
</li>
<li>
<p>backend: Specifies the backend model i.e "diffusers".</p>
<p>Type: str
Options: "diffusers" or "compvis"</p>
</li>
<li>
<p>text_grad: Json that contains lr and weight_decay.</p>
<p>Type: Json
Example: 
<code>json
        "text_grad": {
        "lr": 0.01,
        "weight_decay": 0.1
    }</code></p>
</li>
<li>
<p>attacker</p>
</li>
<li>
<p>insertion_location: The point of insertion for the prompt.</p>
<p>Type: str
Example: "prefix_k"</p>
</li>
<li>
<p>k: The value of k for the prompt insertion point.</p>
<p>Type: int
Example: 5</p>
</li>
<li>
<p>iteration: Number of iterations for the attack.</p>
<p>Type: int
Example: 1</p>
</li>
<li>
<p>seed_iteration: Random seed for the iterative process.</p>
<p>Type: int
Example: 1</p>
</li>
<li>
<p>attack_idx: Index of the attack for evaluation purposes.</p>
<p>Type: int
Example: 0</p>
</li>
<li>
<p>eval_seed: Seed value used for evaluation.</p>
<p>Type: int
Example: 0</p>
</li>
<li>
<p>universal: Whether the attack is universal (true or false).</p>
<p>Type: bool
Example: false</p>
</li>
<li>
<p>sequential: Whether the attack is applied sequentially.</p>
<p>Type: bool
Example: true</p>
</li>
<li>
<p>logger</p>
</li>
<li>
<p>json: Logging configuration.</p>
<ul>
<li>
<p>root: Path to the directory where logs will be saved.</p>
<p>Type: str
Example: "results/seed_search_esd_nudity_P4D"</p>
</li>
<li>
<p>name: Name for the log file or experiment.</p>
<ul>
<li>Type: str</li>
<li>Example: "Seed Search Nudity"</li>
</ul>
</li>
</ul>
<p>Example usage:</p>
<pre><code>"json": {
        "root": "results/text_grad_esd_nudity_esd",
        "name": "TextGradNudity"
    }
</code></pre>
</li>
</ul>
<h4 id="running-the-evaluation-framework"><strong>Running the Evaluation Framework</strong></h4>
<p>Create a file, eg, <code>evaluate.py</code> and use examples and modify your configs to run the evalautions.  </p>
<p><strong>Example Code</strong></p>
<pre><code class="language-python">from evaluation.metrics.asr import asr_score
from evaluation.metrics.clip import clip_score
from evaluation.metrics.fid import fid_score


root = &quot;results/hard_prompt_esd_nudity_P4D_erase_diff/P4d&quot;
root_no_attack =&quot;results/no_attack_esd_nudity_P4D_abstrctionism/NoAttackEsdNudity&quot;

asr_val = asr_score(root, root_no_attack)
print(asr_val)

images = &quot;results/hard_prompt_esd_nudity_P4D_erase_diff_compvis_to_diffuser/P4d/images&quot;
prompt_path = &quot;results/hard_prompt_esd_nudity_P4D_erase_diff_compvis_to_diffuser/P4d/log.json&quot;
device = &quot;0&quot;
clip_val = clip_score(images, prompt_path, device)

print(clip_val)

gen_path = &quot;results/hard_prompt_esd_nudity_P4D_erase_diff/P4d/images&quot;
ref_path = &quot;data/i2p/nude&quot;
fid_val = fid_score(gen_path,ref_path)
print(fid_val)
</code></pre>
<p><strong>Running the Training Script in Offline Mode</strong></p>
<pre><code class="language-bash">WANDB_MODE=offline python evaluate.py
</code></pre>
<p><strong>Evaluation Metrics:</strong></p>
<ul>
<li>
<p>Attack Succes Rate (ASR)</p>
</li>
<li>
<p>Fréchet inception distance(FID): evaluate distributional quality of image generations, lower is better.</p>
</li>
<li>
<p>CLIP score : measure contextual alignment with prompt descriptions, higher is better.</p>
</li>
</ul>
<p><strong>Configuration File Structure for Evaluator</strong></p>
<ul>
<li>
<p>ASR Evaluator Configuration</p>
<ul>
<li>root: Directory containing results with attack.</li>
<li>root-no-attack: Directory containing results without attack.</li>
</ul>
</li>
<li>
<p>Clip Evaluator Configuration</p>
<ul>
<li>image_path: Path to the directory containing generated images to evaluate.</li>
<li>devices: Device ID(s) to use for evaluation. Example: "0" for the first GPU or "0,1" for multiple GPUs.</li>
<li>log_path: Path to the log file containing prompt for the generated images.</li>
<li>model_name_or_path: Path or model name for the pre-trained CLIP model. Default is "openai/clip-vit-base-patch32".</li>
</ul>
</li>
<li>
<p>FID Evaluator Configuration</p>
<ul>
<li>ref_batch_path: Path to the directory containing reference images.</li>
<li>sample_batch_path: Path to the directory containing generated/sample images.</li>
</ul>
</li>
<li>
<p>Global Configuration</p>
<ul>
<li>output_path: Path to save the evaluation results as a JSON file.</li>
</ul>
</li>
</ul>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../configs/seed_search/" class="btn btn-neutral float-left" title="Config"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../configs/text_grad/" class="btn btn-neutral float-right" title="Config">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../configs/seed_search/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../configs/text_grad/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
